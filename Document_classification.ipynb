{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "\n",
        "# Load a pre-trained BERT model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'text': [\n",
        "        'This is a NoC document.',\n",
        "        'This is a birth certificate.',\n",
        "        'This is a death certificate.'\n",
        "    ],\n",
        "    'label': [0, 1, 2]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Tokenize the data\n",
        "inputs = tokenizer(df['text'].tolist(), return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "labels = torch.tensor(df['label'].tolist())\n",
        "\n",
        "dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n",
        "dataloader = DataLoader(dataset, batch_size=2)\n",
        "\n",
        "# Define training function\n",
        "def train(model, dataloader, epochs=3):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for batch in dataloader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f'Epoch {epoch+1}/{epochs} - Loss: {loss.item()}')\n",
        "\n",
        "# Train the model\n",
        "train(model, dataloader)\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained('/content/bert-document-classifier')\n",
        "tokenizer.save_pretrained('/content/bert-document-classifier')\n"
      ],
      "metadata": {
        "id": "U04r5tAQrLlZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}